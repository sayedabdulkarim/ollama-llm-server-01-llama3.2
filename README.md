# Ollama LLM Server on Render

This hosts the `llama3.2:1b` model using Ollama inside a Docker container on Render.
